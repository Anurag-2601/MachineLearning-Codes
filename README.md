# MachineLearning-Codes
This repository contains multiple end-to-end Machine Learning projects, each built using Python and Jupyter Notebooks.
Every notebook demonstrates full ML workflows â€” data loading, cleaning, EDA, preprocessing, model training, evaluation, and insights.

This collection is ideal for:

âœ… ML/AI portfolio

âœ… Academic projects

âœ… Industry preparation

âœ… Demonstrating real data handling skills
<br><br>

ğŸ“‚ Included ML Code:
<br><br>
A)  Supervised Learning Models:
<br><br>
Supervised learning is when we teach a machine using examples that already have the right answers.
It learns from this labeled data so it can make accurate predictions on new information later â€” kind of like learning from past examples to guess future outcomes.

Example: Teaching a model to predict house prices by showing it many houses along with their actual prices.

<br><br>
The Folder Includes :
<br><br>

1. FinancialData.ipynb â€” Loan Default Prediction (XYZCorp Lending Data)


ğŸ“Œ Overview:

Predicts whether a loan defaults based on borrower profile and loan attributes.

â­ Notebook Highlights:

Loaded dataset (73 rows, 246 raw columns)

Removed 200+ unusable â€œUnnamedâ€ columns

Cleaned missing values using median/mode/Unknown

Dropped non-predictive columns (IDs, payment history, descriptions)

One-hot encoded:

âœ… Grade

âœ… Term

âœ… Sub-grade

âœ… Employment length

âœ… Home ownership

âœ… State

âœ… Purpose

Scaled numerical columns using StandardScaler

Trained Logistic Regression

Achieved 82.35% accuracy

Plotted confusion matrix & correlation heatmap

<br><br>
2. banking.ipynb â€” Banking ML Model (Churn/Loan/Customer Behavior)


ğŸ“Œ Overview:

Machine learning model built on a banking dataset for customer behavior prediction.

â­ Notebook Highlights:

Cleaned and formatted customer records

One-hot encoded categorical variables

Balanced dataset using SMOTE

Trained models:

âœ… Logistic Regression

âœ… RandomForest

âœ… Gradient Boosting / XGBoost (if included)

Plotted ROC Curve & confusion matrix

Extracted feature importance
<br><br>

3. cs_intrusion_det.ipynb â€” Cybersecurity Intrusion Detection

ğŸ“Œ Overview:

Builds an Intrusion Detection System (IDS) to detect malicious network traffic.

â­ Notebook Highlights:

Cleaned network traffic dataset

Visualized normal vs attack traffic

Encoded protocol & attack-type fields

Trained ML models:

âœ… Logistic Regression

âœ… SVM

âœ… RandomForest

âœ… DecisionTree

Evaluated model performance

Displayed confusion matrix & classification report
<br><br>

4. heart.ipynb â€” Heart Disease Prediction

ğŸ“Œ Overview:

Predicts heart disease using medical measurements.

â­ Notebook Highlights:

Cleaned and normalized clinical dataset

Explored correlations using heatmaps

Removed outliers

Built models:

âœ… SVM

âœ… KNN

âœ… RandomForest

âœ… DecisionTree

Compared precision, recall, F1-score

Displayed confusion matrix
<br><br>

5. itu_gci.ipynb â€” Global Cybersecurity Index Analysis

ğŸ“Œ Overview:

Analyzes the cybersecurity readiness of countries using ITUâ€™s GCI data.

â­ Notebook Highlights:

Loaded ITU GCI dataset

Ranked countries by cybersecurity index

Visualized top & bottom performers

Regional comparison

Grouped countries by cyber-maturity

Created bar, line, and scatter plots

Extracted key insights about global cyber readiness
<br><br>

6. titanic.ipynb â€” Titanic Survival Prediction
 
ğŸ“Œ Overview:

Predicts whether a passenger survived using demographic and ticket attributes.

â­ Notebook Highlights:

Loaded Titanic dataset

Handled missing values (Age, Cabin, Embarked)

Encoded categorical features (Sex, Embarked, Pclass)

Performed EDA (survival rates by gender/class/age)

Trained multiple models:

âœ… Logistic Regression

âœ… Decision Tree

âœ… RandomForest

Evaluated using accuracy & confusion matrix
<br><br>

ğŸ§  Skills Demonstrated Across All Projects:

âœ… Data Cleaning & Wrangling

âœ… Handling Missing & Imbalanced Data

âœ… One-Hot Encoding & Feature Engineering

âœ… Scaling & Normalization

âœ… Exploratory Data Analysis (EDA)

âœ… Classification Models (LR, SVM, RF, DT, KNN)

âœ… Evaluation Metrics & Visualization

âœ… Working with Financial, Cybersecurity & Healthcare Data
<br><br>

ğŸ›  Technologies Used:

Python 3.x

Pandas, NumPy

Scikit-learn

Seaborn, Matplotlib

Jupyter Notebook

Imbalanced-learn (SMOTE)
<br><br>
B) Unsupervised Learning Models:
<br><br>
Unsupervised learning is when a machine learns from data without any labels or predefined answers.

It tries to find hidden patterns, groups, or structures within the data on its own â€” without being told what the correct output is.
<br><br>
Example: Grouping customers with similar buying habits into clusters without knowing anything about them beforehand.

<br><br>
The Folder Includes:
<br><br>
1. 



<br><br>
ğŸ“¬ Contact:

If you'd like to collaborate or improve any notebook, feel free to create an Issue or Pull Request.
